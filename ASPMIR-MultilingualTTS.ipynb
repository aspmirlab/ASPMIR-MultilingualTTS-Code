{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23e98a8a-7128-4f35-ba1c-ff514ed462e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install All the Required Dependencies\n",
    "#!pip install --upgrade pip \n",
    "#!pip install torch torchvision torchaudio\n",
    "#!pip install transformers ipywidgets gradio --upgrade\n",
    "#!pip install --upgrade transformers accelerate\n",
    "#!pip install --upgrade gradio\n",
    "#!pip install nltk\n",
    "#!pip install soundfile\n",
    "#!pip install librosa numpy jiwer nltk\n",
    "#!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2a7d3a-8c2c-4134-a79f-a3b7b1747874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "from transformers import pipeline\n",
    "from jiwer import wer\n",
    "from transformers import VitsModel, AutoTokenizer, set_seed\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from scipy.spatial.distance import euclidean\n",
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00c8b6da-ed74-4b13-8b1e-cf2774a70dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#Select GPU if available\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set PyTorch CUDA memory allocation strategy\n",
    "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "#print(os.environ.get(\"PYTORCH_CUDA_ALLOC_CONF\")) # Verify that it's set\n",
    "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n",
    "#print(os.environ.get(\"PYTORCH_CUDA_ALLOC_CONF\")) # Verify that it's set\n",
    "\n",
    "#Empty GPU Cache\n",
    "#torch.cuda.empty_cache()\n",
    "#torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "#torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ceb8b4-fe4e-4a97-ac34-dce6a890455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Model Loading Functions\n",
    "description = \"\"\"\n",
    "<div style=\"text-align: center;\">\n",
    "    <h1 style=\"color: #FF0000;\">ASPMIR-MULTILINGUAL-TEXT2SPEECH-TESTBED</h1>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<h3 style=\"color: #D2691E;\">This Tool Allows Developers and Researchers to Carry Out Text2Speech Synthesis with Open Sourced Pretrained/Finetuned Text-to-Speech(TTS) AI Models.</h3>\n",
    "</div>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d64db9-b083-46ae-80ce-9616ba99183d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define Translation and Synthesis Function\n",
    "def speech_synthesis(modelName,langName, langText):\n",
    "    #reference_translations = \"awon apositeli, awon woli, awon ajinrere ati awon oluso agutan ati awon oluko.\" #'recorder_2024-01-13_11-24-41_453538.wav'#\"My name is Joy, I love reading\"\n",
    "    #TTS for the translated_text_target\n",
    "    if \"facebook/mms-tts\" in modelName.lower():\n",
    "        if langName == \"Yoruba\":\n",
    "            ttsModel = VitsModel.from_pretrained(\"facebook/mms-tts-yor\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\"facebook/mms-tts-yor\")\n",
    "            ttsInputs = tokenizer(langText, return_tensors=\"pt\") \n",
    "        elif langName == \"English\":\n",
    "            ttsModel = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n",
    "            ttsInputs = tokenizer(langText, return_tensors=\"pt\")\n",
    "        elif langName == \"French\":\n",
    "            ttsModel = VitsModel.from_pretrained(\"facebook/mms-tts-fra\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\"facebook/mms-tts-fra\")\n",
    "            ttsInputs = tokenizer(langText, return_tensors=\"pt\")\n",
    "        elif langName == \"Hausa\":\n",
    "            ttsModel = VitsModel.from_pretrained(\"facebook/mms-tts-hau\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\"facebook/mms-tts-hau\")\n",
    "            ttsInputs = tokenizer(langText, return_tensors=\"pt\")\n",
    "        elif langName == \"Igbo\":\n",
    "            ttsModel = VitsModel.from_pretrained(\"facebook/mms-tts-ibo\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\"facebook/mms-tts-ibo\")\n",
    "            ttsInputs = tokenizer(langText, return_tensors=\"pt\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model\")\n",
    "    \n",
    "    set_seed(555)  # make deterministic     \n",
    "    with torch.no_grad():\n",
    "        ttsOutput = ttsModel(**ttsInputs).waveform\n",
    "    #Convert the tensor to a numpy array \n",
    "    ttsWaveform = ttsOutput.numpy()[0] \n",
    "    #Save the waveform to an audio file\n",
    "    sf.write('ttsOutput.wav', ttsWaveform, 16000)\n",
    "    return 'ttsOutput.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a83d495c-fe7f-4269-a005-b3f373b97b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_fields():\n",
    "    return \"\", \"\",\"\", None  # Clear modelName, langName, inputText, and audio output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf259d6-922d-4f5c-9af1-cbd57158a814",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "* Running on public URL: https://6234ab7db336428169.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6234ab7db336428169.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1deb69bdce40dca20132b81ac99ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.64k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02223a38e7004951b0f81d86743fc470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/145M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2722630275b1460e932786cb6b5a5fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db84a823df584221b9438e9114ffee25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/374 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735a39eb48a24711a79996121b694da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/47.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Define User Interface Function using Gradio and IPython Libraries\n",
    "import gradio as gr\n",
    "from IPython.display import Audio\n",
    "\n",
    "with gr.Blocks() as interface:\n",
    "    gr.Markdown(description)\n",
    "    with gr.Row():\n",
    "       modelName = gr.Dropdown([\"facebook/mms-tts\"],\n",
    "                               label=\"Select TTS Model\", \n",
    "                               allow_custom_value=True)\n",
    "    with gr.Row():\n",
    "       langName = gr.Dropdown([\"Yoruba\", #Lang1\n",
    "                               \"Hausa\",#Lang2\n",
    "                               \"Igbo\",#Lang2\n",
    "                               \"English\",#Lang2\n",
    "                               \"French\" #Lang2\n",
    "                               ], \n",
    "                               label=\"Select Language for Text2Speech Sythesis\",\n",
    "                               allow_custom_value=True)\n",
    "    with gr.Row():\n",
    "        inputText = gr.Textbox(placeholder=\"Enter Text for Selected Langauge Here...\",label=\"Input Text\", lines=6)\n",
    "    with gr.Row():\n",
    "        btn = gr.Button(\"Generate Speech\")\n",
    "    with gr.Row():\n",
    "        outputAudio = gr.Audio(type=\"filepath\", label=\"Click Play/Pause to Generate Speech for Current Text and Reset Button for New Language Selection/Text Input\")\n",
    "    with gr.Row():\n",
    "        reset_btn = gr.Button(\"Reset\")\n",
    "    btn.click(\n",
    "        fn=speech_synthesis,\n",
    "        inputs= [modelName, langName, inputText],\n",
    "        outputs=outputAudio,\n",
    "    )\n",
    "    reset_btn.click(\n",
    "        fn=reset_fields,\n",
    "        inputs=[],\n",
    "        outputs=[modelName, langName, inputText, outputAudio],\n",
    "    )\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67842334-5c50-48b4-ab8c-8db91aa836ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
